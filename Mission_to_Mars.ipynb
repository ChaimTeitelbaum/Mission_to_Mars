{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook Conversion to Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Executable Path & Initialize Chrome Browser\n",
    "executable_path = {\"executable_path\": \"C:\\webdrivers\\chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASA Mars News Site Web Scraper\n",
    "def mars_news(browser):\n",
    "    # Visit the NASA Mars News Site\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Get First List Item & Wait Half a Second If Not Immediately Present\n",
    "    browser.is_element_present_by_css(\"ul.item_list li.slide\", wait_time=0.5)\n",
    "    \n",
    "    html = browser.html\n",
    "    news_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Parse Results HTML with BeautifulSoup\n",
    "    # Find Everything Inside:\n",
    "    #   <ul class=\"item_list\">\n",
    "    #     <li class=\"slide\">\n",
    "    try:\n",
    "        slide_element = news_soup.select_one(\"ul.item_list li.slide\")\n",
    "        slide_element.find(\"div\", class_=\"content_title\")\n",
    "\n",
    "        # Scrape the Latest News Title\n",
    "        # Use Parent Element to Find First <a> Tag and Save it as news_title\n",
    "        news_title = slide_element.find(\"div\", class_=\"content_title\").get_text()\n",
    "\n",
    "        news_paragraph = slide_element.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "    except AttributeError:\n",
    "        return None, None\n",
    "    return news_title, news_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASA JPL (Jet Propulsion Laboratory) Site Web Scraper\n",
    "def featured_image(browser):\n",
    "    # Visit the NASA JPL (Jet Propulsion Laboratory) Site\n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Ask Splinter to Go to Site and Click Button with Class Name full_image\n",
    "    # <button class=\"full_image\">Full Image</button>\n",
    "    full_image_button = browser.find_by_id(\"full_image\")\n",
    "    full_image_button.click()\n",
    "\n",
    "    # Find \"More Info\" Button and Click It\n",
    "    browser.is_element_present_by_text(\"more info\", wait_time=1)\n",
    "    more_info_element = browser.find_link_by_partial_text(\"more info\")\n",
    "    more_info_element.click()\n",
    "\n",
    "    # Parse Results HTML with BeautifulSoup\n",
    "    html = browser.html\n",
    "    image_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    img = image_soup.select_one(\"figure.lede a img\")\n",
    "    try:\n",
    "        img_url = img.get(\"src\")\n",
    "    except AttributeError:\n",
    "        return None \n",
    "   # Use Base URL to Create Absolute URL\n",
    "    img_url = f\"https://www.jpl.nasa.gov{img_url}\"\n",
    "    return img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Weather Twitter Account Web Scraper\n",
    "def twitter_weather(browser):\n",
    "    # Visit the Mars Weather Twitter Account\n",
    "    url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Parse Results HTML with BeautifulSoup\n",
    "    html = browser.html\n",
    "    weather_soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Find a Tweet with the data-name `Mars Weather`\n",
    "    mars_weather_tweet = weather_soup.find(\"div\", \n",
    "                                       attrs={\n",
    "                                           \"class\": \"tweet\", \n",
    "                                            \"data-name\": \"Mars Weather\"\n",
    "                                        })\n",
    "   # Search Within Tweet for <p> Tag Containing Tweet Text\n",
    "    mars_weather = mars_weather_tweet.find(\"p\", \"tweet-text\").get_text()\n",
    "    return mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Facts Web Scraper\n",
    "def mars_facts():\n",
    "    # Visit the Mars Facts Site Using Pandas to Read\n",
    "    try:\n",
    "        df = pd.read_html(\"https://space-facts.com/mars/\")[0]\n",
    "    except BaseException:\n",
    "        return None\n",
    "    df.columns=[\"Description\", \"Value\"]\n",
    "    df.set_index(\"Description\", inplace=True)\n",
    "\n",
    "    return df.to_html(classes=\"table table-striped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Hemispheres Web Scraper\n",
    "def hemisphere(browser):\n",
    "    # Visit the USGS Astrogeology Science Center Site\n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    hemisphere_image_urls = []\n",
    "\n",
    "    # Get a List of All the Hemisphere\n",
    "    links = browser.find_by_css(\"a.product-item h3\")\n",
    "    for item in range(len(links)):\n",
    "        hemisphere = {}\n",
    "        \n",
    "        # Find Element on Each Loop to Avoid a Stale Element Exception\n",
    "        browser.find_by_css(\"a.product-item h3\")[item].click()\n",
    "        \n",
    "        # Find Sample Image Anchor Tag & Extract <href>\n",
    "        sample_element = browser.find_link_by_text(\"Sample\").first\n",
    "        hemisphere[\"img_url\"] = sample_element[\"href\"]\n",
    "        \n",
    "        # Get Hemisphere Title\n",
    "        hemisphere[\"title\"] = browser.find_by_css(\"h2.title\").text\n",
    "        \n",
    "        # Append Hemisphere Object to List\n",
    "        hemisphere_image_urls.append(hemisphere)\n",
    "        \n",
    "        # Navigate Backwards\n",
    "        browser.back()\n",
    "    return hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def scrape_hemisphere(html_text):\n",
    "    hemisphere_soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    try: \n",
    "        title_element = hemisphere_soup.find(\"h2\", class_=\"title\").get_text()\n",
    "        sample_element = hemisphere_soup.find(\"a\", text=\"Sample\").get(\"href\")\n",
    "    except AttributeError:\n",
    "        title_element = None\n",
    "        sample_element = None \n",
    "    hemisphere = {\n",
    "        \"title\": title_element,\n",
    "        \"img_url\": sample_element\n",
    "    }\n",
    "    return hemisphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Web Scraping Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-04f65ea6933e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-04f65ea6933e>\u001b[0m in \u001b[0;36mscrape_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatured_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmars_weather\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_weather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfacts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmars_facts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mhemisphere_image_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhemisphere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtimestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a2e319be73b7>\u001b[0m in \u001b[0;36mmars_facts\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Description\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Description\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5078\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5079\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5080\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5081\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5082\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    153\u001b[0m             raise ValueError(\n\u001b[0;32m    154\u001b[0m                 \u001b[1;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 3 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "def scrape_all():\n",
    "    executable_path = {\"executable_path\": \"C:\\webdrivers\\chromedriver.exe\"}\n",
    "    browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "    news_title, news_paragraph = mars_news(browser)\n",
    "    img_url = featured_image(browser)\n",
    "    mars_weather = twitter_weather(browser)\n",
    "    facts = mars_facts()\n",
    "    hemisphere_image_urls = hemisphere(browser)\n",
    "    timestamp = dt.datetime.now()\n",
    "\n",
    "    data = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_paragraph\": news_paragraph,\n",
    "        \"featured_image\": img_url,\n",
    "        \"weather\": mars_weather,\n",
    "        \"facts\": facts,\n",
    "        \"hemispheres\": hemisphere_image_urls,\n",
    "        \"last_modified\": timestamp\n",
    "    }\n",
    "    browser.quit()\n",
    "    return data \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(scrape_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
